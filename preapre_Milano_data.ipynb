{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basedir = \"/home/marco/git/webvalley/datapreproc\"\n",
    "#basedir = \"C:/Users/julix/webvalley_git/full_project/data/PLIC-Milano\"\n",
    "basedir = \"/home/mattia/Scrivania/plic_clinical_data/plic_clinical_data/PLIC-Milano\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the smallest dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plic-milano-foglio-piccolo.xlsx is PLIC_1445_V1_V2_V3_V4_linear variables _ updated 15_01_19.xlsx\n",
    "and the plic-milano-foglio-grande.xlsx is PLIC_dataset parametri clinici_V1_V2_V3_V4_1445.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf = pd.read_excel(os.path.join(basedir, \"plic-milano-foglio-piccolo.xlsx\"), index_col=0).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is male and what is female?\n",
    "### Should at least be written in the docs of the whole software otherwise it will be impossible to import new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.sesso.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the biggest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf = pd.read_excel(os.path.join(basedir, \"plic-milano-foglio-grande.xlsx\"), index_col=0).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At least one column is not in the biggest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldfcols = set(smalldf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdfcols = set(bigdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_in_f2 = smalldfcols.intersection(bigdfcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_non_in_f2 = smalldfcols.difference(bigdfcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_in_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_non_in_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1_cols_in_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1_cols_non_in_f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if column names differ because of case sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdfcols_lower = set([k.lower() for k in bigdfcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldfcols_lower = set([k.lower() for k in smalldfcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smalldfcols_lower.intersection(bigdfcols_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is not the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many patients in the smaller dataset are also in the biggest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_smalldf = set(smalldf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_bigdf = set(bigdf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_smalldf.difference(paz_in_bigdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_bigdf.difference(paz_in_smalldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the patients in the small dataset are also in the biggest one*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix known issues with the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets uses different ways to store the data (M/F -> 0/1; Yes/No -> 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf[\"sesso\"] = smalldf[\"sesso\"].map({1: \"F\", 0: \"M\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We dropped all sex errors so the method is appropriate; now replace even Si and No*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all the columns that contains at least one Si or No\n",
    "\n",
    "bool_cols = list()\n",
    "\n",
    "for col in f1_cols_in_f2:\n",
    "    k = getattr(bigdf, col).values\n",
    "    if np.isin(\"Sì\", k) or np.isin(\"No\", k):\n",
    "        bool_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace em all\n",
    "\n",
    "for col in bool_cols:\n",
    "    smalldf[col] = smalldf[col].map({0: \"No\", 1: \"Sì\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Now check if dataset 1 and dataset 2 shared patients contains same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick every patient in the big dataset and check if the values are the same\n",
    "# that are stored in the smaller one\n",
    "\n",
    "for paz_to_be_checked in paz_in_smalldf:\n",
    "    paz_from_big = bigdf.loc[paz_to_be_checked]\n",
    "    paz_from_small = smalldf.loc[paz_to_be_checked]\n",
    "    if not np.array_equal(paz_from_big[f1_cols_in_f2].values, paz_from_small[f1_cols_in_f2].values):\n",
    "        print(\"Paz %s has differences\" % paz_to_be_checked)\n",
    "print(\"check complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding non-duplicate data from smaller dataframe to bigger dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing smaller dataframe to join with bigger dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.drop(f1_cols_in_f2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = bigdf.join(smalldf, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()\n",
    "joined_df['menarca_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trsl = [] #words to translate\n",
    "suff = [] #suffixes -> other words that do not need to be translated (e.g. numbers or strings that are not actual words)\n",
    "\n",
    "#divide suffixes from words to translate\n",
    "for b in joined_df.columns:\n",
    "    a = b.lower().split(\"_\")\n",
    "    c = 0\n",
    "    slist = []\n",
    "    for i in range(len(a),0,-1):\n",
    "        c += 1\n",
    "        if c == 3:\n",
    "            break\n",
    "        else:\n",
    "            if len(a[-1]) <= 2:     #filter for non-words TODO: improve filter\n",
    "                slist.append(a[-1])\n",
    "                a.pop(-1)\n",
    "    slist = slist[::-1]\n",
    "    suff.append(slist)\n",
    "    trsl.append(\" \".join(a))\n",
    "    \n",
    "s = \",\".join(trsl).lower() #string containing italian labels\n",
    "\n",
    "#*copy and paste from google translate the translations of the labels* \n",
    "# NB. google translate accepts only 5000 characters at time, so you'll have to copy and paste several times \n",
    "\n",
    "s = \" visits, standardized visits, death, death, death, date of visit, date of visit, date of visit, date of visit, sex, birth, age, age, age, age, education, education, education, physiological history, menarche, menarche, menarche, menarche, pregnancies, pregnancies, pregnancies, abortion, pregnancies carried to term, menopause, induced, menopause, induced, menopause, induced, menopause age, induced, alcohol, b wine, b beer, b spirits, alcohol , b wine, b beer, b spirits, alcohol, b wine, b beer, b spirits, alcohol, b wine, b beer, b spirits, smoke, smoke 1 recod, smoke, smoke 2 recod, smoke, smoke 3 recod, smoke, smoke 4 recod, physical activity, physical activity intensity, physical activity hours, physical activity, physical activity intensity, physical activity hours, physical activity, physical activity intensity, physical activity hours, physical activity, physical activity intensity, physical activity hours, pathological history, chd, chd, chd, chd, chd profile, remote chd, remote chd, remote chd, remote chd, angina, angina date, angina, date angina, angina, date angina, angina, date angina, profile angina, remote angina, remote angina, remote angina, remote angina, silent ischemia, data silent ischemia, silent ischemia, silent ischemia date, silent ischemia, ischemia silent data, silent ischemia, given silent ischemia, silent profile ischemia, remote silent ischemia, remote silent ischemia, remote silent ischemia, remote silent ischemia, ima, ima date, ima, ima date, ima date, ima, ima date, ima date profile, remote ima, remote ima, remote ima, remote ima, bypass, data bypass, bypass, data bypass, bypass, data bypass, bypass, data bypass, profile bypass, remote bypass, remote bypass, remote bypass, remote bypass, ptca, ptca date, ptca, ptca date, ptca, ptca date, ptca, ptca date, ptca profile, remote ptca, remote ptca, remote ptca, remote ptca, stroke, date stroke, stroke, stroke date, stroke, date stroke, stroke, stroke date, stroke profile, remote stroke, remote stroke, remote stroke, remote stroke, tia, date tia, tia, date tia, tia, date tia, tia, date tia, tia profile, tia remote, tia remote, remote thia, remote thia, peripheral arterial disease, given peripheral arterial disease, peripheral arteriopathy, given peripheral arterial disease, peripheral arterial disease, given peripheral arterial disease, tsa data peripheral arteriopathy, peripheral arterial disease, peripheral arterial disease , remote peripheral arterial disease, remote peripheral artery disease, remote peripheral artery disease, aortic artery disease, aortic artery disease, aortic artery disease, aortic artery disease, aortic artery disease, aortic artery disease, aortic artery disease, artery disease, aortic artery disease remote aortic, remote aortic arteriopathy, atrial fibrillation, given atrial fibrillation, atrial fibrillation, given atrial fibrillation, atrial fibrillation, given atrial fibrillation, atrial fibrillation, given atrial fibrillation, arrhythmia, given arrhythmia, arrhythmia given, Arith ie major, major arrhythmias data, ivs, ivs, ivs, ivs data, ivs, ivs date, decompensation, decompensation given, decompensation, decompensation given, decompensation, decompensation given, decompensation, decompensation given, remote decompensation, remote decompensation, remote decompensation, remote decompensation, venous thrombosis, given venous thrombosis, venous thrombosis, venous thrombosis, venous thrombosis, given venous thrombosis, venous thrombosis, venous thrombosis, cerebral haemorrhage, given cerebral hemorrhage, cerebral hemorrhage, cerebral hemorrhage, cerebral hemorrhage data, cerebral haemorrhage, given cerebral hemorrhage, self hypertension, self data hypertension, self hypertension, self data hypertension, self hypertension, self data hypertension, self hypertension, self data hypertension, self diabetes, self diabetes1 self data , diabetes1 self, diabetes1 self data, diabetes1 self, diabetes1 self data, diabetes2 self, diabetes2 self data, diabetes2 self, diabetes2 self data, diabetes2 self, diabetes2 self data, diabetes2 self, diabetes2 self data, obesity self, self data obesity, self obesity, self data obesity, self obesity, self data obesity, self obesity, self data obesity, self dyslipidemia, self data dyslipidemia, self data dyslipidemia, self data dyslipidemia, self dyslipidemia , self type dyslipidemia, self data dyslipidemia, new revaluation diagnosis, new revaluation diagnosis, xanthomatosis, given xanthomatosis, xanthomatosis, given xanthomatosis, xanthomatosis, given xanthomatosis, xanthomatosis, given xanthomatosis, nephropathy, nephropathy, given nephropathy, nephropathy, type nephropathy, nephropathy given, nephropathy, nephropathy type, nephropathy given, nephropathy, nephropathy type, nephropathy given, nephropathy profile, thyroid disease, thyroid function, thyroid disease, thyroid disease, thyroid function, thyroid disease, thyroid function , thyroid disease, thyroid disease, thyroid function, thyroid disease, liver disease, liver disease, given liver disease, hepatopathic diseases and, type hepatopathies\"\n",
    "\n",
    "s = s.replace(\" and\",\"e\").replace(\"given\",\"date\").replace(\"data\",\"date\").replace(\"b \",\"drinks \") #apply some corrections\n",
    "\n",
    "s = [a[1:] for a in s.split(\",\")] #remove space before word\n",
    "\n",
    "#reattach the suffixes\n",
    "i = 0\n",
    "for sub in s:\n",
    "    sub = sub.replace(\" \",\"_\") + \"_\" + \"_\".join(suff[i])\n",
    "    print(sub)\n",
    "    i += 1\n",
    "\n",
    "#joined_df['arteriopatia_aortica_data_4'].unique()      \n",
    "#[b.lower() for b in joined_df.columns]\n",
    "#trsl\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e1 = examination 1\n",
    "#anamnesi fisiologica = physiological_medical_history\n",
    "#mearca = \n",
    "#NB. What is istruzione?\n",
    "#\n",
    "new_labels = [\"carried_out_examinations\",\n",
    "              \"a_standardized_carried_out_examinations\",\n",
    "              \"death_e1_e2\", #ask\n",
    "              \"death_e2_e3\",\n",
    "              \"death_e3_e4\",\n",
    "              \"e1_date\",\n",
    "              \"e2_date\",\n",
    "              \"e3_date\",\n",
    "              \"e4_date\",\n",
    "              \"gender\",\n",
    "              \"birth_date\",\n",
    "              \"e1_age\",\n",
    "              \"e2_age\",\n",
    "              \"e3_age\",\n",
    "              \"e4_age\",\n",
    "              \"e1_education\",\n",
    "              \"e2_education\",\n",
    "              \"e3_education\",\n",
    "              \"e4_education\"\n",
    "              \"physiological_medical_history\",\n",
    "              \"e1_first_menstruation_age\",\n",
    "              \"e2_first_menstruation_age\",\n",
    "              \"e3_first_menstruation_age\",\n",
    "              \"e4_first_menstruation_age\",\n",
    "              \"e1_n_pregnancies\",\n",
    "              \"e2_n_pregnancies\",\n",
    "              \"e3_n_pregnancies\",\n",
    "              \"e4_n_pregnancies\",\n",
    "              \"e4_n_abortion\",#why only e4?\n",
    "              \"e4_n_completed_pregnancies\",\n",
    "              \"e1_menopause_age\",\n",
    "              \"e1_menopause_induced\",\n",
    "              \"e2_menopause_age\",\n",
    "              \"e2_menopause_induced\",\n",
    "              \"e3_menopause_age\",\n",
    "              \"e3_menopause_induced\",\n",
    "              \"e4_menopause_age\",\n",
    "              \"e4_menopause_induced\",\n",
    "              \"e1_alcohol_consumption\",\n",
    "              \"e1_wine\",\n",
    "              \"e1_beer\",\n",
    "              \"e1_super_alcoholic\"]\n",
    "              \n",
    "              \n",
    "              \n",
    "              \n",
    "              \n",
    "print(\"The end.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
