{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basedir = \"/home/marco/git/webvalley/datapreproc\"\n",
    "basedir = \"C:/Users/julix/webvalley_git/full_project/data/PLIC-Milano\"\n",
    "#basedir = \"/home/mattia/Scrivania/plic_clinical_data/plic_clinical_data/PLIC-Milano\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the smallest dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plic-milano-foglio-piccolo.xlsx is PLIC_1445_V1_V2_V3_V4_linear variables _ updated 15_01_19.xlsx\n",
    "and the plic-milano-foglio-grande.xlsx is PLIC_dataset parametri clinici_V1_V2_V3_V4_1445.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf = pd.read_excel(os.path.join(basedir, \"plic-milano-foglio-piccolo.xlsx\"), index_col=0).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is male and what is female?\n",
    "### Should at least be written in the docs of the whole software otherwise it will be impossible to import new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.sesso.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the biggest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf = pd.read_excel(os.path.join(basedir, \"plic-milano-foglio-grande.xlsx\"), index_col=0).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At least one column is not in the biggest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldfcols = set(smalldf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdfcols = set(bigdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_in_f2 = smalldfcols.intersection(bigdfcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_non_in_f2 = smalldfcols.difference(bigdfcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_in_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_non_in_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1_cols_in_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1_cols_non_in_f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if column names differ because of case sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdfcols_lower = set([k.lower() for k in bigdfcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldfcols_lower = set([k.lower() for k in smalldfcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smalldfcols_lower.intersection(bigdfcols_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is not the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many patients in the smaller dataset are also in the biggest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_smalldf = set(smalldf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_bigdf = set(bigdf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_smalldf.difference(paz_in_bigdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_bigdf.difference(paz_in_smalldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the patients in the small dataset are also in the biggest one*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix known issues with the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets uses different ways to store the data (M/F -> 0/1; Yes/No -> 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf[\"sesso\"] = smalldf[\"sesso\"].map({1: \"F\", 0: \"M\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We dropped all sex errors so the method is appropriate; now replace even Si and No*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all the columns that contains at least one Si or No\n",
    "\n",
    "bool_cols = list()\n",
    "\n",
    "for col in f1_cols_in_f2:\n",
    "    k = getattr(bigdf, col).values\n",
    "    if np.isin(\"Sì\", k) or np.isin(\"No\", k):\n",
    "        bool_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace em all\n",
    "\n",
    "for col in bool_cols:\n",
    "    smalldf[col] = smalldf[col].map({0: \"No\", 1: \"Sì\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Now check if dataset 1 and dataset 2 shared patients contains same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick every patient in the big dataset and check if the values are the same\n",
    "# that are stored in the smaller one\n",
    "\n",
    "for paz_to_be_checked in paz_in_smalldf:\n",
    "    paz_from_big = bigdf.loc[paz_to_be_checked]\n",
    "    paz_from_small = smalldf.loc[paz_to_be_checked]\n",
    "    if not np.array_equal(paz_from_big[f1_cols_in_f2].values, paz_from_small[f1_cols_in_f2].values):\n",
    "        print(\"Paz %s has differences\" % paz_to_be_checked)\n",
    "\n",
    "print(\"check complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding non-duplicate data from smaller dataframe to bigger dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing smaller dataframe to join with bigger dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.drop(f1_cols_in_f2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = bigdf.join(smalldf, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()\n",
    "joined_df['menarca_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rid of empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = list()\n",
    "for i in joined_df.columns.values:\n",
    "    o = joined_df[i].unique()\n",
    "    if len(o) == 1 and o[0] == -1:\n",
    "        cols_to_drop.append(i)\n",
    "\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns ```_<int:pk>``` and divide patients visits on different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in joined_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = [\"_%s\" % a for a in range(0,10)] + \\\n",
    "           [\"_%s_a\" % a for a in range(0,10)] + \\\n",
    "           [\"_%s_recod\" % a for a in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_cols = [x for x in joined_df.columns if x.endswith(tuple(suffixes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mv_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perdurant_cols = [x for x in joined_df.columns if x not in mv_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = set()\n",
    "\n",
    "for col in mv_cols:\n",
    "    for s in suffixes:\n",
    "        col = col.replace(s, \"\")\n",
    "    col.replace(\"__\", \"_\")\n",
    "    if col.endswith(\"_\"):\n",
    "        col = col[:-1]\n",
    "    new_cols.add(col)\n",
    "\n",
    "for col in perdurant_cols:\n",
    "    new_cols.add(col)\n",
    "\n",
    "new_cols.add(\"cod_pz\")\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new dataframe with the defined columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_per_visit = set()\n",
    "\n",
    "for col in mv_cols:\n",
    "    for s in suffixes:\n",
    "        col = col.replace(s, re.sub(\"\\d\", \"%s\", s))\n",
    "    fields_per_visit.add(col)\n",
    "\n",
    "fields_per_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "for col in [a % b for a in fields_per_visit for b in range(1, 5)]:\n",
    "    if col not in joined_df.columns.values:\n",
    "        print(\"Cannot find\", col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check we do have the same number of cols as before\n",
    "len([k for k in [a % b for a in fields_per_visit for b in range(1, 5)] if k in joined_df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the new dataframe with the data from the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary to convert multicols names into singlecol\n",
    "single = dict()\n",
    "\n",
    "for col in mv_cols:\n",
    "    _col = col\n",
    "    for s in suffixes:\n",
    "        col = col.replace(s, \"\")\n",
    "    col.replace(\"__\", \"_\")\n",
    "    if col.endswith(\"_\"):\n",
    "        col = col[:-1]\n",
    "    single[_col] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([k in new_cols for k in single.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for paz in joined_df.index.values:\n",
    "        obj = joined_df.loc[paz]\n",
    "        for visit in range(1, 5):\n",
    "            this = {\"cod_pz\": paz}\n",
    "            for old_col in fields_per_visit:\n",
    "                try:\n",
    "                    this[single[old_col % visit]] = obj[old_col % visit]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            for pd_col in perdurant_cols:\n",
    "                this[pd_col] = obj[pd_col]\n",
    "            new_data.append(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo = pd.DataFrame(new_data, columns=new_cols).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = set()\n",
    "mask_fields = set()\n",
    "for col in pippo.columns.values:\n",
    "    if len(pippo[col].unique())<10:\n",
    "        print(col, pippo[col].unique())\n",
    "        mask_fields.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = {\n",
    "    \"NR\": -1,\n",
    "    \"campo vuoto\": -1,\n",
    "    \"mancante\": -1,\n",
    "    \"No\": 0,\n",
    "    \"Sì\": 1,\n",
    "    \"Si\": 1,\n",
    "    \"no\": 0,\n",
    "    \"sì\": 1,\n",
    "    \"si\": 1,\n",
    "    \"presenti\": 1,\n",
    "    \"assenti\": 0,\n",
    "    \"assente\": 0,\n",
    "    \"completo\": 1,\n",
    "    \"incompleto\": 2,\n",
    "    \"sì - saltuario\": 1,\n",
    "    \"sì - regolare\": 2,\n",
    "    \"non palpabile\": 0,\n",
    "    \"palpabile\": 1,\n",
    "    \"normale\": 0,\n",
    "    \"patologico\": 1,\n",
    "    \"nessuna\": 0,\n",
    "    \"leggera\": 1,\n",
    "    \"media\": 2,\n",
    "    \"pesante\": 3,\n",
    "    \"ex\": 2,\n",
    "    \"F\": 1,\n",
    "    \"M\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mask_fields:\n",
    "    if pippo[col].dtype == np.object_:\n",
    "        pippo[col] = pippo[col].replace(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_clist = list(pippo.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_clist = sorted(ita_clist, key=lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([x.replace(\"_a\", \"\").replace(\"_\", \" \") for x in ita_clist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation from DeepL\n",
    "\n",
    "\n",
    "```\n",
    "ABI dx calc\n",
    "ABI mean calc\n",
    "ABI sx calc\n",
    "abortion n\n",
    "abdomen\n",
    "abdomen type\n",
    "AGRATIO\n",
    "alcohols\n",
    "HIGH\n",
    "height\n",
    "other pathologies\n",
    "Android perc\n",
    "angina\n",
    "angina date\n",
    "angina profile\n",
    "remote angina a\n",
    "antiaggregants to\n",
    "antidiabetics to\n",
    "antihypertensive to\n",
    "aorta calcifications\n",
    "apoA1\n",
    "apoB\n",
    "respiratory system\n",
    "right corneal arch\n",
    "left corneal arch\n",
    "arrhythmia\n",
    "arrhythmia date\n",
    "major arrhythmias\n",
    "major arrhythmias date\n",
    "aortic arteriopathy\n",
    "aortic arteriopathy date\n",
    "remote aortic arteriopathy a\n",
    "peripheral arteriopathy\n",
    "peripheral arteriopathy limbs\n",
    "peripheral arteriopathy given limbs\n",
    "peripheral arteriopathy given\n",
    "remote peripheral arteriopathy a\n",
    "peripheral arteriopathy TSA\n",
    "peripheral arteriopathy TSA given\n",
    "extremities\n",
    "AST\n",
    "ATT ATC1\n",
    "ATT ATC2\n",
    "ATT ATC3\n",
    "ATT start date1\n",
    "ATT start date2\n",
    "ATT start date3\n",
    "ATT indication1\n",
    "ATT PA1\n",
    "ATT PA2\n",
    "ATT PA3\n",
    "physical activity\n",
    "physical activity intensity\n",
    "physical activity hours\n",
    "b Beer\n",
    "b spirits\n",
    "b wine\n",
    "basophils\n",
    "basophils percent\n",
    "BMC g\n",
    "BMD g\n",
    "BMI calc\n",
    "body scan data\n",
    "COPD\n",
    "COPD date\n",
    "bypass\n",
    "bypass date\n",
    "Profile bypass\n",
    "remote bypass to\n",
    "CHD\n",
    "CHD profile\n",
    "Remote CHD to\n",
    "clearance CG calc\n",
    "cod pcs\n",
    "cholecystectomy\n",
    "cholecystectomy date\n",
    "conc hb cell medium\n",
    "CPK\n",
    "creatinine\n",
    "TORQUE AND ANGLE WRENCH\n",
    "cyanosis skin\n",
    "cute oedemas\n",
    "skin hematomas\n",
    "skin infections\n",
    "pale skin\n",
    "tofi skin\n",
    "cute xanthelasms\n",
    "Cute Xanthomas\n",
    "date endothelium\n",
    "date of withdrawal\n",
    "date TIA\n",
    "date of visit\n",
    "diabetes1 self\n",
    "diabetes1 self data\n",
    "diabetes2 self\n",
    "diabetes2 self data\n",
    "diagnosis of new revaluations\n",
    "endothelial dysfunction\n",
    "self dyslipidaemia\n",
    "self data dyslipidemia\n",
    "self type dyslipidemia\n",
    "DM ATC1\n",
    "DM ATC2\n",
    "DM ATC3\n",
    "DM ATC4\n",
    "DM start date1\n",
    "DM start date2\n",
    "DM start date3\n",
    "DM start date4\n",
    "DM PA1\n",
    "DM PA2\n",
    "DM PA3\n",
    "DM PA4\n",
    "Dys ATC1\n",
    "Dys ATC2\n",
    "Dys start date1\n",
    "Dys start date2\n",
    "Dys PA1\n",
    "Dys PA2\n",
    "EA\n",
    "EA Low\n",
    "ECOSTEATOSIS ECOCARDIO\n",
    "hematocrit\n",
    "haemoglobin\n",
    "hemoglobin cell medium\n",
    "cerebral hemorrhage\n",
    "cerebral hemorrhage given\n",
    "eosinophils\n",
    "eosinophils percent\n",
    "hepatopathies date\n",
    "hepatopathies NS\n",
    "hepatopathies type\n",
    "erythrocytes\n",
    "ages\n",
    "NS Drugs\n",
    "FE\n",
    "enlarged liver\n",
    "flanks\n",
    "fibers a\n",
    "atrial fibrillation\n",
    "given atrial fibrillation\n",
    "FMD\n",
    "heart rate\n",
    "smoking\n",
    "smoking recod\n",
    "gGT\n",
    "ginoid perc\n",
    "glucose\n",
    "epicardial fat\n",
    "fat g\n",
    "pregnancies n\n",
    "completed pregnancies\n",
    "HDL\n",
    "HT ATC1\n",
    "HT ATC2\n",
    "HT ATC3\n",
    "HT ATC4\n",
    "HT ATC5\n",
    "HT start date1\n",
    "HT start date2\n",
    "HT start date3\n",
    "HT start date4\n",
    "HT indication1\n",
    "HT PA1\n",
    "HT PA2\n",
    "HT PA3\n",
    "HT PA4\n",
    "HT PA5\n",
    "strokes\n",
    "stroke date\n",
    "Stroke Profile\n",
    "Remote stroke at\n",
    "IMA\n",
    "IMA date\n",
    "IMA profile\n",
    "Remote IMA at\n",
    "IMT DC max\n",
    "IMT CC max right\n",
    "IMT CC max left\n",
    "IMT DC medium\n",
    "IMT DC medium right\n",
    "IMT CC medium left\n",
    "diagnostic investigations1 date\n",
    "diagnostic investigations1 outcome\n",
    "diagnostic investigations1 type examination\n",
    "diagnostic investigations2 date\n",
    "diagnostic investigations2 outcome\n",
    "diagnostic investigations2 type examination\n",
    "diagnostic investigations3 date\n",
    "diagnostic investigations3 outcome\n",
    "diagnostic investigations3 type examination\n",
    "induced\n",
    "hypertension self\n",
    "hypertension self data\n",
    "silent ischaemia\n",
    "ischemia silente date\n",
    "ischaemia silent profile\n",
    "remote silent ischemia a\n",
    "learning\n",
    "IVS\n",
    "IVS date\n",
    "LDL calc\n",
    "leukocytes\n",
    "lymphocytes\n",
    "lymphocytes percent\n",
    "Lunar NS\n",
    "lean g\n",
    "menarche\n",
    "menopause\n",
    "menopause age\n",
    "monocytes\n",
    "monocytes percent\n",
    "MVS\n",
    "emergence\n",
    "nephropathy date\n",
    "nephropathies NS\n",
    "nephropathies profile\n",
    "nephropathies type\n",
    "neoplasm1 date\n",
    "neoplasm1 NS\n",
    "neoplasm1 operated on\n",
    "neoplasm1 therapy\n",
    "neoplasm1 type\n",
    "neoplasm2 given\n",
    "neoplasm2 NS\n",
    "neoplasm2 operated\n",
    "neoplasia2 therapy\n",
    "neoplasm2 type\n",
    "given neoplasm\n",
    "NS neoplasm\n",
    "type neoplasm\n",
    "neutrophils\n",
    "neutrophils percent\n",
    "well-known\n",
    "known endothelium\n",
    "self obesity\n",
    "obesity self data\n",
    "OT ATC1\n",
    "USED OT ATC10\n",
    "OT ATC11\n",
    "OT ATC12\n",
    "OT ATC2\n",
    "OT ATC3\n",
    "OT ATC4\n",
    "OT ATC5\n",
    "OT ATC6\n",
    "OT ATC7\n",
    "OT ATC8\n",
    "OT ATC9\n",
    "PA ankle right\n",
    "PA left ankle\n",
    "pad\n",
    "pancreas\n",
    "pancreatopathy given\n",
    "pancreatopathy NS\n",
    "pancreatopathy type\n",
    "pas\n",
    "PCR\n",
    "burden\n",
    "plates\n",
    "PLACA\n",
    "right plate NS\n",
    "left plate NS\n",
    "peripheral arterial wrists\n",
    "SECONDARY PREVENTION\n",
    "PTCA\n",
    "PTCA date\n",
    "PTCA profile\n",
    "Remote PTCA to\n",
    "RDW CV\n",
    "RDW SD\n",
    "imbalance\n",
    "decompensation date\n",
    "remote decompensation at\n",
    "gender\n",
    "SIV\n",
    "NS blows\n",
    "blow type\n",
    "statins a\n",
    "steatosis\n",
    "steatosis degree\n",
    "steatosis NS\n",
    "fabric g\n",
    "fabric perc\n",
    "TG\n",
    "TIA\n",
    "TIA profile\n",
    "Remote TIA to\n",
    "thyroid appearance\n",
    "thyroid function\n",
    "thyroid nodules\n",
    "thyroid pathologies date\n",
    "thyroid pathologies text\n",
    "venous thrombosis\n",
    "venous thrombosis given\n",
    "U TSA date\n",
    "uricemia\n",
    "urine date\n",
    "visits carried out\n",
    "standardised visits to\n",
    "lifetime\n",
    "waist hips calc\n",
    "vol cell medium\n",
    "xanthomatosis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_clist = \"\"\"ABI dx calc\n",
    "ABI mean calc\n",
    "ABI sx calc\n",
    "abortion n\n",
    "abdomen\n",
    "abdomen type\n",
    "AGRATIO\n",
    "alcohols\n",
    "HIGH\n",
    "height\n",
    "other pathologies\n",
    "Android perc\n",
    "angina\n",
    "angina date\n",
    "angina profile\n",
    "remote angina a\n",
    "antiaggregants to\n",
    "antidiabetics to\n",
    "antihypertensive to\n",
    "aorta calcifications\n",
    "apoA1\n",
    "apoB\n",
    "respiratory system\n",
    "right corneal arch\n",
    "left corneal arch\n",
    "arrhythmia\n",
    "arrhythmia date\n",
    "major arrhythmias\n",
    "major arrhythmias date\n",
    "aortic arteriopathy\n",
    "aortic arteriopathy date\n",
    "remote aortic arteriopathy a\n",
    "peripheral arteriopathy\n",
    "peripheral arteriopathy limbs\n",
    "peripheral arteriopathy given limbs\n",
    "peripheral arteriopathy given\n",
    "remote peripheral arteriopathy a\n",
    "peripheral arteriopathy TSA\n",
    "peripheral arteriopathy TSA given\n",
    "extremities\n",
    "AST\n",
    "ATT ATC1\n",
    "ATT ATC2\n",
    "ATT ATC3\n",
    "ATT start date1\n",
    "ATT start date2\n",
    "ATT start date3\n",
    "ATT indication1\n",
    "ATT PA1\n",
    "ATT PA2\n",
    "ATT PA3\n",
    "physical activity\n",
    "physical activity intensity\n",
    "physical activity hours\n",
    "b Beer\n",
    "b spirits\n",
    "b wine\n",
    "basophils\n",
    "basophils percent\n",
    "BMC g\n",
    "BMD g\n",
    "BMI calc\n",
    "body scan data\n",
    "COPD\n",
    "COPD date\n",
    "bypass\n",
    "bypass date\n",
    "Profile bypass\n",
    "remote bypass to\n",
    "CHD\n",
    "CHD profile\n",
    "Remote CHD to\n",
    "clearance CG calc\n",
    "cod pcs\n",
    "cholecystectomy\n",
    "cholecystectomy date\n",
    "conc hb cell medium\n",
    "CPK\n",
    "creatinine\n",
    "total cholesterol\n",
    "cyanosis skin\n",
    "cute oedemas\n",
    "skin hematomas\n",
    "skin infections\n",
    "pale skin\n",
    "tofi skin\n",
    "cute xanthelasms\n",
    "Cute Xanthomas\n",
    "date endothelium\n",
    "date of withdrawal\n",
    "date TIA\n",
    "date of visit\n",
    "diabetes1 self\n",
    "diabetes1 self data\n",
    "diabetes2 self\n",
    "diabetes2 self data\n",
    "diagnosis of new revaluations\n",
    "endothelial dysfunction\n",
    "self dyslipidaemia\n",
    "self data dyslipidemia\n",
    "self type dyslipidemia\n",
    "DM ATC1\n",
    "DM ATC2\n",
    "DM ATC3\n",
    "DM ATC4\n",
    "DM start date1\n",
    "DM start date2\n",
    "DM start date3\n",
    "DM start date4\n",
    "DM PA1\n",
    "DM PA2\n",
    "DM PA3\n",
    "DM PA4\n",
    "Dys ATC1\n",
    "Dys ATC2\n",
    "Dys start date1\n",
    "Dys start date2\n",
    "Dys PA1\n",
    "Dys PA2\n",
    "EA\n",
    "EA Low\n",
    "ECOSTEATOSIS ECOCARDIO\n",
    "hematocrit\n",
    "haemoglobin\n",
    "hemoglobin cell medium\n",
    "cerebral hemorrhage\n",
    "cerebral hemorrhage given\n",
    "eosinophils\n",
    "eosinophils percent\n",
    "hepatopathies date\n",
    "hepatopathies NS\n",
    "hepatopathies type\n",
    "erythrocytes\n",
    "age\n",
    "NS Drugs\n",
    "FE\n",
    "enlarged liver\n",
    "flanks\n",
    "fibers a\n",
    "atrial fibrillation\n",
    "given atrial fibrillation\n",
    "FMD\n",
    "heart rate\n",
    "smoking\n",
    "smoking recod\n",
    "gGT\n",
    "ginoid perc\n",
    "glucose\n",
    "epicardial fat\n",
    "fat g\n",
    "pregnancies n\n",
    "completed pregnancies\n",
    "HDL\n",
    "HT ATC1\n",
    "HT ATC2\n",
    "HT ATC3\n",
    "HT ATC4\n",
    "HT ATC5\n",
    "HT start date1\n",
    "HT start date2\n",
    "HT start date3\n",
    "HT start date4\n",
    "HT indication1\n",
    "HT PA1\n",
    "HT PA2\n",
    "HT PA3\n",
    "HT PA4\n",
    "HT PA5\n",
    "strokes\n",
    "stroke date\n",
    "Stroke Profile\n",
    "Remote stroke at\n",
    "IMA\n",
    "IMA date\n",
    "IMA profile\n",
    "Remote IMA at\n",
    "IMT DC max\n",
    "IMT CC max right\n",
    "IMT CC max left\n",
    "IMT DC medium\n",
    "IMT DC medium right\n",
    "IMT CC medium left\n",
    "diagnostic investigations1 date\n",
    "diagnostic investigations1 outcome\n",
    "diagnostic investigations1 type examination\n",
    "diagnostic investigations2 date\n",
    "diagnostic investigations2 outcome\n",
    "diagnostic investigations2 type examination\n",
    "diagnostic investigations3 date\n",
    "diagnostic investigations3 outcome\n",
    "diagnostic investigations3 type examination\n",
    "induced\n",
    "hypertension self\n",
    "hypertension self data\n",
    "silent ischaemia\n",
    "ischemia silente date\n",
    "ischaemia silent profile\n",
    "remote silent ischemia a\n",
    "learning\n",
    "IVS\n",
    "IVS date\n",
    "LDL calc\n",
    "leukocytes\n",
    "lymphocytes\n",
    "lymphocytes percent\n",
    "Lunar NS\n",
    "lean g\n",
    "menarche\n",
    "menopause\n",
    "menopause age\n",
    "monocytes\n",
    "monocytes percent\n",
    "MVS\n",
    "birth\n",
    "nephropathy date\n",
    "nephropathies NS\n",
    "nephropathies profile\n",
    "nephropathies type\n",
    "neoplasm1 date\n",
    "neoplasm1 NS\n",
    "neoplasm1 operated on\n",
    "neoplasm1 therapy\n",
    "neoplasm1 type\n",
    "neoplasm2 given\n",
    "neoplasm2 NS\n",
    "neoplasm2 operated\n",
    "neoplasia2 therapy\n",
    "neoplasm2 type\n",
    "given neoplasm\n",
    "NS neoplasm\n",
    "type neoplasm\n",
    "neutrophils\n",
    "neutrophils percent\n",
    "well-known\n",
    "known endothelium\n",
    "self obesity\n",
    "obesity self data\n",
    "OT ATC1\n",
    "USED OT ATC10\n",
    "OT ATC11\n",
    "OT ATC12\n",
    "OT ATC2\n",
    "OT ATC3\n",
    "OT ATC4\n",
    "OT ATC5\n",
    "OT ATC6\n",
    "OT ATC7\n",
    "OT ATC8\n",
    "OT ATC9\n",
    "PA ankle right\n",
    "PA left ankle\n",
    "pad\n",
    "pancreas\n",
    "pancreatopathy given\n",
    "pancreatopathy NS\n",
    "pancreatopathy type\n",
    "pas\n",
    "PCR\n",
    "burden\n",
    "plates\n",
    "plaque\n",
    "right plate NS\n",
    "left plate NS\n",
    "peripheral arterial wrists\n",
    "SECONDARY PREVENTION\n",
    "PTCA\n",
    "PTCA date\n",
    "PTCA profile\n",
    "Remote PTCA to\n",
    "RDW CV\n",
    "RDW SD\n",
    "imbalance\n",
    "decompensation date\n",
    "remote decompensation at\n",
    "gender\n",
    "SIV\n",
    "NS blows\n",
    "blow type\n",
    "statins a\n",
    "steatosis\n",
    "steatosis degree\n",
    "steatosis NS\n",
    "fabric g\n",
    "fabric perc\n",
    "TG\n",
    "TIA\n",
    "TIA profile\n",
    "Remote TIA to\n",
    "thyroid appearance\n",
    "thyroid function\n",
    "thyroid nodules\n",
    "thyroid pathologies date\n",
    "thyroid pathologies text\n",
    "venous thrombosis\n",
    "venous thrombosis given\n",
    "U TSA date\n",
    "uricemia\n",
    "urine date\n",
    "visits carried out\n",
    "standardised visits to\n",
    "lifetime\n",
    "waist hips calc\n",
    "vol cell medium\n",
    "xanthomatosis\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len([a for a in pippo]) == len(en_clist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dict = {\"given\":\"date\", \n",
    "              \"data\" : \"date\", \n",
    "              \"IMT DC\":\"IMT CC\", \n",
    "              \"learning\":\"education\", \n",
    "              \"cod_pcs\":\"subject_id\", \n",
    "              \"cod_pz\":\"subject_id\", \n",
    "              \"fabric\":\"tissue\", \n",
    "              \"blow\":\"bruit\", \n",
    "              \"blows\":\"bruit\", \n",
    "              \"flanks\":\"hips\", \n",
    "              \"well-known\":\"notes\", \n",
    "              \"withdrawal\":\"sampling\", \n",
    "              \"burden\":\"weight\", \n",
    "              \"pas\":\"SBP\", \n",
    "              \"pas\":\"DPB\", \n",
    "              \"MVS\":\"LBM\",\n",
    "              \"medium\":\"average\", \n",
    "              \"known endothelium\":\"endothelium notes\",\n",
    "              \"AGRATIO\":\"AG-RATIO\", \n",
    "              \"Agratio\":\"AG-ratio\"\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = [\"self\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in en_clist:\n",
    "    for w in trans_dict:\n",
    "        if w in i:\n",
    "            i.replace(w, trans_dict[w])\n",
    "        for s in sl:\n",
    "            if s in i:\n",
    "                i.replace(s, \"\")\n",
    "                i = i + \" \" + s\n",
    "                i.replace(\"  \", \" \")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo = pippo[ita_clist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.columns = [en_clist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.to_csv(os.path.join(basedir, \"PLIC-milano-processed-and-translated.csv\"), sep=\";\")\n",
    "#pippo.to_csv(\"/out_Milano.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The end.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
