{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"/home/marco/git/webvalley/datapreproc\"\n",
    "#basedir = \"C:/Users/julix/webvalley_git/full_project/data/PLIC-Milano\"\n",
    "#basedir = \"/home/mattia/Scrivania/plic_clinical_data/plic_clinical_data/PLIC-Milano\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the smallest dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plic-milano-foglio-piccolo.xlsx is PLIC_1445_V1_V2_V3_V4_linear variables _ updated 15_01_19.xlsx\n",
    "and the plic-milano-foglio-grande.xlsx is PLIC_dataset parametri clinici_V1_V2_V3_V4_1445.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf = pd.read_excel(os.path.join(basedir, \"plic-milano-foglio-piccolo.xlsx\"), index_col=0).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is male and what is female?\n",
    "### Should at least be written in the docs of the whole software otherwise it will be impossible to import new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.sesso.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the biggest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf = pd.read_excel(os.path.join(basedir, \"plic-milano-foglio-grande.xlsx\"), index_col=0).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At least one column is not in the biggest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldfcols = set(smalldf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdfcols = set(bigdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_in_f2 = smalldfcols.intersection(bigdfcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_non_in_f2 = smalldfcols.difference(bigdfcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_in_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cols_non_in_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1_cols_in_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1_cols_non_in_f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if column names differ because of case sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdfcols_lower = set([k.lower() for k in bigdfcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldfcols_lower = set([k.lower() for k in smalldfcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smalldfcols_lower.intersection(bigdfcols_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is not the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many patients in the smaller dataset are also in the biggest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_smalldf = set(smalldf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_bigdf = set(bigdf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_smalldf.difference(paz_in_bigdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paz_in_bigdf.difference(paz_in_smalldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the patients in the small dataset are also in the biggest one*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix known issues with the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets uses different ways to store the data (M/F -> 0/1; Yes/No -> 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf[\"sesso\"] = smalldf[\"sesso\"].map({1: \"F\", 0: \"M\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We dropped all sex errors so the method is appropriate; now replace even Si and No*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all the columns that contains at least one Si or No\n",
    "\n",
    "bool_cols = list()\n",
    "\n",
    "for col in f1_cols_in_f2:\n",
    "    k = getattr(bigdf, col).values\n",
    "    if np.isin(\"Sì\", k) or np.isin(\"No\", k):\n",
    "        bool_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace em all\n",
    "\n",
    "for col in bool_cols:\n",
    "    smalldf[col] = smalldf[col].map({0: \"No\", 1: \"Sì\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Now check if dataset 1 and dataset 2 shared patients contains same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick every patient in the big dataset and check if the values are the same\n",
    "# that are stored in the smaller one\n",
    "\n",
    "for paz_to_be_checked in paz_in_smalldf:\n",
    "    paz_from_big = bigdf.loc[paz_to_be_checked]\n",
    "    paz_from_small = smalldf.loc[paz_to_be_checked]\n",
    "    if not np.array_equal(paz_from_big[f1_cols_in_f2].values, paz_from_small[f1_cols_in_f2].values):\n",
    "        print(\"Paz %s has differences\" % paz_to_be_checked)\n",
    "\n",
    "print(\"check complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding non-duplicate data from smaller dataframe to bigger dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing smaller dataframe to join with bigger dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.drop(f1_cols_in_f2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = bigdf.join(smalldf, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()\n",
    "joined_df['menarca_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rid of empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = list()\n",
    "for i in joined_df.columns.values:\n",
    "    o = joined_df[i].unique()\n",
    "    if len(o) == 1 and o[0] == -1:\n",
    "        cols_to_drop.append(i)\n",
    "\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns ```_<int:pk>``` and divide patients visits on different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in joined_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = [\"_%s\" % a for a in range(0,10)] + \\\n",
    "           [\"_%s_a\" % a for a in range(0,10)] + \\\n",
    "           [\"_%s_recod\" % a for a in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_cols = [x for x in joined_df.columns if x.endswith(tuple(suffixes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mv_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perdurant_cols = [x for x in joined_df.columns if x not in mv_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = set()\n",
    "\n",
    "for col in mv_cols:\n",
    "    for s in suffixes:\n",
    "        col = col.replace(s, \"\")\n",
    "    col.replace(\"__\", \"_\")\n",
    "    if col.endswith(\"_\"):\n",
    "        col = col[:-1]\n",
    "    new_cols.add(col)\n",
    "\n",
    "for col in perdurant_cols:\n",
    "    new_cols.add(col)\n",
    "\n",
    "new_cols.add(\"cod_pz\")\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new dataframe with the defined columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_per_visit = set()\n",
    "\n",
    "for col in mv_cols:\n",
    "    for s in suffixes:\n",
    "        col = col.replace(s, re.sub(\"\\d\", \"%s\", s))\n",
    "    fields_per_visit.add(col)\n",
    "\n",
    "fields_per_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "for col in [a % b for a in fields_per_visit for b in range(1, 5)]:\n",
    "    if col not in joined_df.columns.values:\n",
    "        print(\"Cannot find\", col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check we do have the same number of cols as before\n",
    "len([k for k in [a % b for a in fields_per_visit for b in range(1, 5)] if k in joined_df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the new dataframe with the data from the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary to convert multicols names into singlecol\n",
    "single = dict()\n",
    "\n",
    "for col in mv_cols:\n",
    "    _col = col\n",
    "    for s in suffixes:\n",
    "        col = col.replace(s, \"\")\n",
    "    col.replace(\"__\", \"_\")\n",
    "    if col.endswith(\"_\"):\n",
    "        col = col[:-1]\n",
    "    single[_col] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([k in new_cols for k in single.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for paz in joined_df.index.values:\n",
    "        obj = joined_df.loc[paz]\n",
    "        for visit in range(1, 5):\n",
    "            this = {\"cod_pz\": paz}\n",
    "            for old_col in fields_per_visit:\n",
    "                try:\n",
    "                    this[single[old_col % visit]] = obj[old_col % visit]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            for pd_col in perdurant_cols:\n",
    "                this[pd_col] = obj[pd_col]\n",
    "            new_data.append(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo = pd.DataFrame(new_data, columns=new_cols).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = set()\n",
    "mask_fields = set()\n",
    "for col in pippo.columns.values:\n",
    "    if len(pippo[col].unique())<10:\n",
    "        print(col, pippo[col].unique())\n",
    "        mask_fields.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = {\n",
    "    \"NR\": -1,\n",
    "    \"campo vuoto\": -1,\n",
    "    \"mancante\": -1,\n",
    "    \"No\": 0,\n",
    "    \"Sì\": 1,\n",
    "    \"Si\": 1,\n",
    "    \"no\": 0,\n",
    "    \"sì\": 1,\n",
    "    \"si\": 1,\n",
    "    \"presenti\": 1,\n",
    "    \"assenti\": 0,\n",
    "    \"assente\": 0,\n",
    "    \"completo\": 1,\n",
    "    \"incompleto\": 2,\n",
    "    \"sì - saltuario\": 1,\n",
    "    \"sì - regolare\": 2,\n",
    "    \"non palpabile\": 0,\n",
    "    \"palpabile\": 1,\n",
    "    \"normale\": 0,\n",
    "    \"patologico\": 1,\n",
    "    \"nessuna\": 0,\n",
    "    \"leggera\": 1,\n",
    "    \"media\": 2,\n",
    "    \"pesante\": 3,\n",
    "    \"ex\": 2,\n",
    "    \"F\": 1,\n",
    "    \"M\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mask_fields:\n",
    "    if pippo[col].dtype == np.object_:\n",
    "        pippo[col] = pippo[col].replace(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pippo.to_csv(\"/tmp/out_Milano.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The end.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pippo[\"data_visita\"][pippo[\"data_visita\"].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
