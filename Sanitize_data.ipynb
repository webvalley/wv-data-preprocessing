{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plic_import_error(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plic_importer:\n",
    "    nan_value = -1\n",
    "    sep = \",\"\n",
    "    index_col = 0\n",
    "    \n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.df = None\n",
    "        self.map_dict = {}\n",
    "        \n",
    "    def excel_to_pandas_df(self):\n",
    "        return pd.read_excel(self.file_name, index_col=self.index_col).fillna(self.nan_value)       \n",
    "        \n",
    "    def csv_to_pandas_df(self):\n",
    "        return pd.read_csv(self.file_name, index_col=self.index_col, sep=self.sep).fillna(self.nan_value) \n",
    "    \n",
    "    def drop_empty_cols(self):\n",
    "        cols_to_drop = []\n",
    "        \n",
    "        for i in self.df.columns.values:\n",
    "            o = self.df[i].unique()\n",
    "            if len(o) == 1 and o[0] == -1:\n",
    "                cols_to_drop.append(i)\n",
    "        \n",
    "        self.df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "                \n",
    "    def visit_cols_to_rows(self):\n",
    "        suffixes = [\"_%s\" % a for a in range(0,10)] + \\\n",
    "           [\"_%s_a\" % a for a in range(0,10)] + \\\n",
    "           [\"_%s_recod\" % a for a in range(0,10)]\n",
    "        \n",
    "        mv_cols = [x for x in self.df.columns if x.endswith(tuple(suffixes))]\n",
    "        perdurant_cols = [x for x in self.df.columns if x not in mv_cols]\n",
    "        \n",
    "        new_cols = set()\n",
    "        \n",
    "        for col in mv_cols:\n",
    "            for s in suffixes:\n",
    "                col = col.replace(s, \"\")\n",
    "            col.replace(\"__\", \"_\")\n",
    "            if col.endswith(\"_\"):\n",
    "                col = col[:-1]\n",
    "            new_cols.add(col)\n",
    "\n",
    "        for col in perdurant_cols:\n",
    "            new_cols.add(col)\n",
    "\n",
    "        new_cols.add(\"cod_pz\")\n",
    "        \n",
    "        fields_per_visit = set()\n",
    "\n",
    "        for col in mv_cols:\n",
    "            for s in suffixes:\n",
    "                col = col.replace(s, re.sub(\"\\d\", \"%s\", s))\n",
    "            fields_per_visit.add(col)\n",
    "            \n",
    "        single = dict()\n",
    "\n",
    "        for col in mv_cols:\n",
    "            _col = col\n",
    "            for s in suffixes:\n",
    "                col = col.replace(s, \"\")\n",
    "            col.replace(\"__\", \"_\")\n",
    "            if col.endswith(\"_\"):\n",
    "                col = col[:-1]\n",
    "            single[_col] = col\n",
    "        \n",
    "        new_data = []\n",
    "\n",
    "        for paz in self.df.index.values:\n",
    "                obj = self.df.loc[paz]\n",
    "                for visit in range(1, 5):\n",
    "                    this = {\"cod_pz\": paz}\n",
    "                    for old_col in fields_per_visit:\n",
    "                        try:\n",
    "                            this[single[old_col % visit]] = obj[old_col % visit]\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "                    for pd_col in perdurant_cols:\n",
    "                        this[pd_col] = obj[pd_col]\n",
    "                    new_data.append(this)\n",
    "        \n",
    "        self.df = pd.DataFrame(new_data, columns=new_cols).fillna(self.nan_value)\n",
    "        \n",
    "    def convert_string_values(self):\n",
    "        yes_no = {\"No\": 0,\n",
    "                \"Sì\": 1,\n",
    "                \"Si\": 1,\n",
    "                \"no\": 0,\n",
    "                \"sì\": 1,\n",
    "                \"si\": 1,\n",
    "                \"F\": 1,\n",
    "                \"M\": 0,\n",
    "                \"mancante\": -1,\n",
    "                 -1: -1,\n",
    "                 -1.0: -1}\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for col in self.df.columns.values:\n",
    "            if self.df[col].dtypes == \"object_\":                \n",
    "                remove_list = [\"-1\", -1, -1.0]\n",
    "                unique_list = [str(item) for item in self.df[col].unique() if item not in remove_list]\n",
    "                \n",
    "                if all([x in yes_no.keys() for x in unique_list]):\n",
    "                    self.df[col] = self.df[col].map(yes_no)\n",
    "                    \n",
    "                elif \"data\" not in col and len(unique_list) < 8:\n",
    "                    enc_value_list = le.fit_transform(unique_list)\n",
    "                    col_map_dict = dict(zip(unique_list, [x+2 for x in enc_value_list]))\n",
    "                    self.df[col] = self.df[col].map(col_map_dict)\n",
    "                    self.map_dict[col] = col_map_dict\n",
    "                    \n",
    "        self.df = self.df.fillna(self.nan_value)\n",
    "        \n",
    "    def drop_useless_columns(self):\n",
    "        bad_col_contains = [\"note\", \"endotelio\", \n",
    "                        \"indagini\", \"tiroide_patologie_text\", \n",
    "                        \"neoplasia_tipo\", \"altre_patologie\", \n",
    "                        \"nefropatie_tipo\", \"diagnosi_nuove_rivalutazioni\", \n",
    "                        \"addome_tipo\", \"neoplasia1_tipo\", \"soffi_tipo\", \n",
    "                        \"HT_indicazione1\",  \"epatopatie_tipo\"]\n",
    "        bad_col_list = []\n",
    "        \n",
    "        for c in self.df.columns.values:\n",
    "            if any([x in c for x in bad_col_contains]):\n",
    "                bad_col_list.append(c)\n",
    "\n",
    "        self.df.drop(bad_col_list, axis=1, inplace=True)\n",
    "\n",
    "    def fix_useful_string_columns(self):\n",
    "        self.fix_EA()\n",
    "        self.fix_fumo()\n",
    "        self.fix_grasso_epicardico()\n",
    "        self.fix_date_objects()\n",
    "    \n",
    "    def fix_EA(self):\n",
    "        self.df[\"EA\"].replace(\"FA\", -1, inplace=True)\n",
    "        self.df[\"EA\"].replace(\"fa\", -1, inplace=True)\n",
    "        self.df[\"EA\"] = self.df[\"EA\"].astype(\"float64\")\n",
    "\n",
    "    def fix_fumo(self):\n",
    "        new_values = []\n",
    "        for value in self.df[\"fumo\"]:\n",
    "            if \"no\" in value:\n",
    "                new_values.append(0)\n",
    "            elif \"ex\" in value:\n",
    "                new_values.append(2)\n",
    "            else:\n",
    "                new_values.append(1)\n",
    "        \n",
    "        self.df[\"fumo\"] = new_values\n",
    "    \n",
    "    def fix_grasso_epicardico(self):\n",
    "        foglio_grande.df[\"grasso_epicardico\"] = foglio_grande.df[\"grasso_epicardico\"].apply(lambda s: str(s).replace(\",\", \".\"))\n",
    "    \n",
    "    def fix_date_objects(self):\n",
    "        cur_year = datetime.now().year\n",
    "        for col in self.df.columns.values:\n",
    "            if \"data\" in col:\n",
    "                new_value_list = []\n",
    "                for val in self.df[col]:\n",
    "                    if type(val) not in [pd._libs.tslibs.timestamps.Timestamp, np.datetime64]:\n",
    "                        q = str(val).replace(\"?\", \"\").strip().split(\".\")[0]\n",
    "                        if len(q) == 4:\n",
    "                            if 1900 <= int(q) <= cur_year:\n",
    "                                new_value_list.append(datetime(int(q), month=1, day=1, hour=0, minute=0))\n",
    "                            else:\n",
    "                                new_value_list.append(-1)\n",
    "                        else:\n",
    "                            new_value_list.append(-1)\n",
    "                    \n",
    "                    else:\n",
    "                        new_value_list.append(val)\n",
    "                self.df[col] = new_value_list\n",
    "\n",
    "    def translate_cols(self):\n",
    "        transfile = pd.read_excel(\"cols_trans.xlsx\", index_col=0)\n",
    "        tr_dict = {}\n",
    "        for idx, row in transfile.iterrows():\n",
    "            tr_dict[row.IT] = row.EN\n",
    "        new_cols_names = []\n",
    "        for col in self.df.columns.values:\n",
    "            if col in tr_dict:\n",
    "                new_cols_names.append(tr_dict[col])\n",
    "            else:\n",
    "                new_cols_names.append(col)\n",
    "        self.df.columns = new_cols_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foglio_grande = Plic_importer(\"C:\\\\Users\\\\julix\\\\webvalley_git\\\\full_project\\\\data\\\\PLIC-Milano\\\\plic-milano-foglio-grande.xlsx\")\n",
    "foglio_grande = Plic_importer(\"/home/marco/git/webvalley/datapreproc/plic-milano-foglio-grande.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.df = foglio_grande.excel_to_pandas_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.drop_empty_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/t214oaWEu9s?start=66\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.visit_cols_to_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.convert_string_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.drop_useless_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.fix_useful_string_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.translate_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foglio_grande.df.to_excel(\"/tmp/testout.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
